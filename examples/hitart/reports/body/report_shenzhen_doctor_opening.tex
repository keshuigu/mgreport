% !Mode:: "TeX:UTF-8"
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                          _
%  _____ ____ _ _ __  _ __| |___ ___
% / -_) \ / _` | '  \| '_ \ / -_|_-<
% \___/_\_\__,_|_|_|_| .__/_\___/__/
%                    |_|
%  _              _         _   _
% | |__ _  _   __| |_  _ __| |_(_)_ _  __ _  _ ___
% | '_ \ || | / _` | || (_-<  _| | ' \/ _| || (_-<
% |_.__/\_, | \__,_|\_,_/__/\__|_|_||_\__|\_, /__/
%       |__/                              |__/
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{课题来源及研究的背景和意义}
\subsection{课题来源}
本研究课题来源项目：人工智能安全模型及评估方法研究
\par
项目编号：MH20200818
\subsection{研究的背景及意义}
近年来，随着科技的快速发展，处理器变得越来越强大，存储器变得越来越便宜，针对各种应用程序的大型图像数据库的部署已经成为现实。由于互联网上的图像信息迅速增长。图像检索技术在各个领域得到了广泛的应用。
基于内容的图像检索\cite{2015Content}（Content Based Image Retrieval，CBIR）是基于颜色、纹理和形状等视觉特征的图像检索。存储在数据库中的每个图像都被提取其特征并与查询图像的特征进行比较。
基于内容的图像检索应用方向十分多样：（1）安全检查：利用指纹或视网膜扫描等生物信息以获取访问权限；（2）知识产权：商标图像注册，将新的候选标记与现有标记进行比较，以确保没有混淆财产所有权的风险；（3）医疗诊断：在医学图像的医学数据库中使用基于内容的图像检索技术，识别类似的过去病例来辅助诊断。
\par
基于内容的图像检索技术依赖于图像局部特征提取技术。这项技术是从图像中提取出能够表征图像局部结构和纹理信息的特征点的方法。‌这些特征点通常具有旋转、‌尺度缩放、‌亮度变化等不变性，对视角变化、‌仿射变换、‌噪声也保持一定程度的稳定性。‌常见的图像局部特征提取算法包括‌尺度不变特征变换\cite{loweDistinctiveImageFeatures2004}（Scale-invariant feature transform，SIFT）、定向梯度直方图\cite{1467360}（Histogram of Oriented Gradients，HOG）‌、局部二值模式\cite{1017623}（Local Binary Patterns，LBP）‌等。‌这些算法通过检测图像中的关键点或角点，并提取其周围的局部图像块信息，生成特征信息，用于后续的图像匹配、‌检索等任务。

\par
由于图像特征提取技术的广泛使用，与图像特征相关的隐私和安全问题也引起了高度关注\cite{9762698}\cite{Qin2014TowardsEP}。事实证明，图像特征包括了丰富的图像信息，攻击者可以根据图像特征来获取隐私信息\cite{10214250}\cite{10.1145/3386082}。另外一篇具有代表性的工作\cite{5995616}表明，可以从一个图像的局部描述符来重建图像，重建后的图像能够表现出人类可理解的内容。
因此，通过利用图像特征进行重建图像的攻击具备了可行性。考虑以下情景：在一个图像检索服务场景中，由于本地计算设备限制以及隐私需求，用户仅将待查询图像的图像特征传输到远程服务提供商。远程服务提供商使用用户上传的图像特征进行基于内容的图像检索，最终将检索到的图像返回给用户，从而完成一次图像检索。
假设在这个过程中攻击者可以获取到用户上传的图像特征。那么，攻击者可以用该图像特征作为输入，利用自己的攻击模型生成与原始图像视觉效果近似的图像\cite{10.1145/3599589.3599596}\cite{SUN2020102642}，从而窃取用户的隐私信息。
\par
本课题主要以攻击者的角度来关注图像特征的隐私泄露问题。针对目前已有的基于图像特征进行反向重建图像的攻击方法所存在的各个问题，从高效率的图像特征反向攻击方法、高精准度的图像特征反向攻击方法的角度分别进行研究。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{国内外在该方向的研究现状及分析}
本章将从图像特征反向攻击研究现状、图像生成模型研究现状描述当前的国内外研究现状并简析。
\subsection{针对图像特征的反向攻击研究现状}

在针对图像特征反向攻击的研究方面，早期的研究工作是由Weinzaepfel\cite{5995616}等人首先完成的。他们建立了保存图像补丁与特征点的外部数据库，使用数据库中数据来拼接图像补丁，完成重建原始图像的任务，证明了从SIFT这类特征恢复图像的可行性。
Angelo\cite{6460288}等人提出了一种反向优化框架，该框架能够仅依赖特征描述符携带的信息来恢复图像，他们的结果表明导致最佳重建的描述符也会导致最佳检索结果。
Vondrick\cite{Vondrick_2013_ICCV}等人提出了一种基于词典学习的方法来可视化HOG形式的图像特征描述符，该方法在各种不同的本地特征之间表现出了高度的可移植性。
Desolneux\cite{10.1007/978-3-319-58771-4_11}等人提出了两种基于泊松图像编辑和多尺度方向场组合的重建模型。这些模型能够恢复图像的全局形状和许多几何细节,但无需使用任何外部数据库。
Katod\cite{Kato_2014_CVPR}等人表明，可以从词袋（Bag of Visual Words, BoVW）表示中的稀疏局部描述符恢复一些原始图像结构。他们使用大规模的图像数据库来估计局部描述符的空间排列，将重建任务转换为了一个关于视觉单词的邻接和全局定位成本的拼图问题。
\par
随着深度神经网络的广泛，许多基于深度学习的图像特征反向攻击方法被提出。
Mahendrand\cite{Mahendran_2015_CVPR}等人提出了一种基于神经网络的重建图像通用框架，显著提高了重建图像的效果。
Dosovitski\cite{Dosovitskiy_2016_CVPR}等人的工作将各类特征提取技术视为编码器，利用卷积神经网络设计对应的解码器。结果表明除了对SIFT，HOG，LBP这类浅层特征提取技术重建图像有效外，该模型也可以从卷积神经网络的深层特征出发重建图像。
Pittaluga\cite{Pittaluga_2019_CVPR}等人训练了一个基于U-Net结构的级联网络，从局部特征中揭示场景。该网络有效地处理高度稀疏和不规则的二维点分布以及具有缺失点属性的输入。
Wu\cite{9393327}等人通过使用生成对抗网络体系结构作为模型主干，同时利用LBP特征来弥补SIFT特征在表示图像空间结构方面的局限性，提出了一种深度生成模型。该模型由两个网络组成：一个是LBP重建网络，其目的是将SIFT图像特征变换为LBP图像特征；另一个是图像重建网络，它以变换后的LBP为指导产生重建结果，提高了重建图像的效果。
另外，Pittaluga\cite{Pittaluga_2023_ICCV}等人最近的一项工作提出了基于数据库的反向攻击和基于聚类的反向攻击，结果表明了即便对SIFT等特征进行后处理，仍然保留了恢复原始图像内容的可行性。
Li\cite{liDeepReverseAttack2024}等人基于GAN模型，构建了一个两阶段的条件引导生成模型，他们重新设计了生成模型的损失函数，加入了对SIFT特征的衡量。重建图像的过程分为两步，首先利用SIFT生成大致的图像，再把该图像和SIFT特征共同作为二阶段模型的输入，使用多尺度融合技术来增强图像细节。结果表明了重建图像的效果更优。
\par
综上所述，目前效果较好的图像特征反向攻击方法为基于生成式模型所进行反向攻击，因此，有必要对生成模型进行进一步的研究。
\subsection{图像生成模型研究现状}
目前有三个主流的图像生成模型研究方向，分别是基于似然的模型，生成对抗网络以及基于能量的模型\cite{luoUnderstandingDiffusionModels2022}。
基于似然的模型，主要目标是学习为观察到的数据样本分配高似然的模型，代表的模型有自回归模型、流模型和变分自动编码器。
生成对抗网络模型中一般包括判别器和生成器共同运行，其中生成器根据隐空间采样数据生成一个图像，判别器则用于区分生成的图像与原始的图像。训练过程中，生成器和判别器的相互对抗，生成器所学习到的分布逐渐靠近原始图像分布。
基于能量的模型又称扩散模型，扩散模型一般由前向扩散过程和反向生成过程组成。其中前向扩散过程将图像逐步添加噪声直至变成随机噪声，反向生成过程则将随机噪声逐步去除噪声直至生成图像数据。
\par
在基于似然的模型方面，Kingma\cite{kingmaAutoEncodingVariationalBayes2022}等人提出了变分自编码器(Variational Auto-Encoder, VAE)模型，通过变分贝叶斯方法，将对原始图像数据的负对数似然的建模优化转为变分下界的计算。VAE模型包含编码器和解码器，其中编码器将原始图像映射到隐变量，解码器从采样的隐变量重建原始图像。
Sohn\cite{sohnLearningStructuredOutput2015}等人在VAE的基础上提出了条件变分自编码器(Conditional Variational Auto-Encoder, CVAE) 模型，其在VAE的基础上，引入条件概率，使得在生成时能够按照标签条件生成。VAE与CVAE的区别在于数据产生方式，VAE是从隐变量采样后使用网络生成图像数据，而CVAE使用标签采样隐变量，再使用网络生成图像数据。
Van\cite{vandenoordNeuralDiscreteRepresentation2017}等人提出了向量量化变分自编码器(VectorQuantisation Variational Auto-Encoder, VQ-VAE)，其在VAE基础上，采用了离散的隐变量，并单独训练一个自回归模型来学习隐变量的先验分布。相比于原始的VAE，VQ-VAE采用了离散编码，并且用了两阶段来生成，让隐变量的先验分布从高斯分布变成可学习的分布，提升了模型的学习能力。
\par
生成对抗模型(Generative Adversarial Networks, GAN)是由Goodfellow\cite{goodfellowGenerativeAdversarialNetworks2014}等人提出。这类模型主要是通过一个生成器G和一个判别器D的双方博弈完成训练。对于判别器而言，其优化期望能区分输入图像是生成图像的概率；对于生成器而言，其优化期望是能生成判别器难以分辨真伪的图像。
Arjovsky\cite{arjovskyWassersteinGAN2017}等人提出WGAN(Wasserstein GAN,WGAN)模型，该文献认为原始GAN模型的损失函数中使用的对称的JS散度不能很好体现两个分布之间的差距，使得在初始阶段分布差距过大时难以训练，而KL散度对生成器训练阶段的多样性与真实性的惩罚贡献不均衡，使得模型发生模式崩溃而难以生成多样性的样本。这项工作中使用了Wasserstein距离代替了JS散度，解决训练稳定性问题。
Esser\cite{esserTamingTransformersHighResolution2021}等人在VQ-VAE的基础上，将其隐变量生成器从pixelCNN换成了Transformer，并且在训练过程中加入使用PatchGAN的判别器以及对抗损失。通过使用Transformer做离散编码的生成器，隐变量的预测过程可以被视作自回归预测。经实验，VQGAN可以很好的完成高分辨图像的生成任务。

\par
在扩散模型方面，Ho\cite{hoDenoisingDiffusionProbabilistic2020}等人提出了第一个正式的去噪扩散模型(Denoising Diffusion Probabilistic Models, DDPM)，其包含一个前向的扩散过程和一个反向的生成过程。前向扩散过程中，将原始图像数据按马尔可夫过程据逐步添加随机噪声，最终变成纯随机噪声；在反向生成过程中，将噪声数据每次去噪并采样，逐步恢复原始数据。DDPM对整个扩散生成过程建模，经过优化将问题转变为预测每一步的随机噪声，并采用神经网络对噪声预测拟合。
Song\cite{songGenerativeModelingEstimating2019}等人提出了条件噪声得分网络(Noise-Conditional Score Networks, NCSN)，其主要思路为分数匹配方法来估算数据分布的分数函数，并通过朗之万动力学采样实现采样生成。由于数据位于高维空间中的低维流行上，难以估计分数函数，则该文献提出了使用不同程度的噪声对其扰动，并联合估计分数函数。该工作可以视为DDPM扩散模型的另一种解释。
Song\cite{songScoreBasedGenerativeModeling2021}等人针对扩散模型，提出了Score SDE框架统一并且解释了扩散模型。该文献从分数匹配与能量模型角度，提出了基于随机微分方程(StochasticDifferential Equations, SDE) 的去噪分数匹配模型。不同于DDPM的离散形式，使用随机微分方程建模的ScoreSDE是连续形式，正向过程通过SDE求解来注入噪声，将图像数据分布转换到已知的先验分布，并使用神经网络模型学习分数，反向过程通过预测并修正的采样方案，最终将噪声去除并从先验分布转换到数据分布。该文献不仅提出模型，并且将以往的DDPM模型和基于得分匹配朗之万动力学模型都统一使用SDE模型表达，实现了对扩散模型的解释与统一。
Rombach\cite{rombachHighResolutionImageSynthesis2022}等人提出了隐扩散模型 LDM(Latent Diffusion Models, LDM)，因以往的扩散模型直接在图像空间扩散与训练，对计算资源、运算时间消耗大，LDM在隐空间作扩散训练，通过预训练的自编码模型来实现对图像像素空间与隐空间的转换。其中还内嵌条件生成机制，可以在模型中引入多种形态的条件机制，如文本、标签、语音、图像等条件信息。经过实验，其在图像生成、超分辨率、图像修复等诸多下游任务都有很好的表现。
\par
除了以上三类模型，在条件生成模型方面，还有不少工作取得了效果显著的成果。Radford \cite{pmlr-v139-radford21a}等提出文图对比预训练模型CLIP(Contrastive Language-Image Pre-training, CLIP)，为基于对比学习的多模态模型。该模型使用文本编码器和图像编码器，将文本与图像编码到相似的隐空间中。该文献打通了文本与图像的隔阂，将两者统一起来，后续许多工作的研究都采用了 CLIP 的引导实现的文生图与图生图功能。
Ramesh \cite{pmlr-v139-ramesh21a}等人提出了DALL-E模型，这是一个由OpenAI开发的文本描述生成图像模型。该模型首先使用VAE思路将图像编码为离散的隐变量，用Transformer模型将自然语言映射到隐变量，最后将隐变量融合成并使用解码器生成图像，通过CLIP辅助计算文本与图像的相关度。其中的VAE、Transformer和CLIP都可以独立完成训练学习。
\par
大语言模型（Large Language Models，LLM）出现后，条件引导图像生成的研究工作中涌现出了一个新的思路，即利用现成预训练好的大语言模型去生成图像，因此产生了多模态大模型\cite{zhang2024mmllmsrecentadvancesmultimodal}。
Alayrac\cite{NEURIPS2022_960a172b}等人基于70B参数的Chinchilla大语言模型，训练出的Flamingo模型在5个任务达到了领先的水平。目前的效果较好的生成模型规模普遍较大，训练过程长，所需资源多。为了解决根据下游任务重新训练大模型代价昂贵的问题，Hu\cite{hu2021loralowrankadaptationlarge}等人提出了低秩适应（Low-rank Adaptation，LoRA）技术，通过冻结了预训练的模型权重，并将可训练的秩分解矩阵注入到 Transformer 架构的每一层中，大大减少了利用大模型进行下游任务的可训练参数的数量。LoRA作为一种有效的适应策略，既不会引入推理延迟，也不会减少输入序列长度，同时保持高模型质量。重要的是，通过共享绝大多数模型参数，它可以在部署为服务时实现快速任务切换。该项工作指出其所提出的原理通常适用于任何具有密集层的神经网络。

\subsection{国内外文献综述的简析}
目前已有的针对图像特征进行反向攻击的工作可以分为传统方法和基于深度学习的方法。传统方法作为这一领域的开创性工作，证明了通过图像特征进行反向攻击的可能性。但是传统方法的图像重建效果普遍较差，且部分方法依赖于需要耗费大量精力准备的外部数据库，在实现上存在较大的不足。基于深度学习的方法虽然取得了优于传统方法的效果，但它们在充分揭示图像特征中包含的信息方面仍然存在局限性，并且重建图像的质量还没有达到令人满意的程度。近年来，图像生成模型快速发展，利用生成对抗网络结构构建的反向攻击模型在进行针对图像特征的反向重建图像攻击任务中表现出了不错的效果，但这类基于生成对抗网络结构的模型训练困难、不稳定，且重建图像的效果仍有提升空间。扩散模型作为另一种形式的图像生成模型，也逐渐取得了能够与生成对抗网络系列模型相对抗的图像生成成果。与此同时，大语言模型的发展也推动了多模态模型的发展，如今基于大语言模型的文生图多模态大模型不但打通了文本与图像的隔阂，还在多项任务中取得了领先的效果。与之伴随着的多模态微调技术可以利用已有的预训练多模态模型对特定领域的知识进行学习，使其能够泛化到不同的研究领域。这一技术为不同模态之间的转换提供了新的思路，可以将多模态模型微调作为建立图像特征反向攻击的新的思路。
\par
综合本节内容，目前仍然需要对针对图像特征的反向攻击方法的作进一步研究，以提升利用图像特征来重建图像的效果和效率。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{主要研究内容及研究方案}
\subsection{主要研究内容}
本节主要介绍本课题的两个主要研究内容，包括高精准度的图像特征反向攻击方法研究、高效率的图像特征反向攻击方法研究。
\subsubsection{高精准度的图像特征反向攻击方法研究}
图像特征反向攻击指的是将未知图像的图像特征信息作为输入，利用该信息生成出新的图像，目的是希望该图像尽可能接近原始图像。在过去的研究方法中，通过结合生成式模型的方法已经取得了一定的成果。然而，这种方法仍然存在以下两个可能的问题：（1）图像重建效果不够好，生成图像模糊，与原数据较大差距。（2）模型对图像特征中包含的信息未能充分利用，理解存在局限性。如使用GAN系列结构，由于GAN结构中生成过程为一步式生成，所提供的图像特征信息可能不足以对图像重建产生足够的约束。
\par
针对以上现存的问题，需要针对高精准度的图像特征反向攻击方法作出研究。一方面，需要提升图像重建的质量，另一方面，需要提升模型对图像特征信息的理解能力，以实现高精准度的图像特征反向攻击。

\subsubsection{高效率的图像特征反向攻击方法研究}
传统的图像特征反向攻击方法多基于外部数据库进行图像拼接以完成重建，而基于生成式模型的图像特征反向攻击效果较好的方法主要采用对抗网络方法辅助生成。于是产生如下可能的问题（1） 基于生成对抗网络辅助生成的方法，一方面生成对抗网络不是直接对目标数据分布建模，而是使用对抗式训练方法来衡量分布相似度，对数据分布的建模可能不够准确；另一方面生成对抗网络在训练时，存在难以训练难以收敛的问题，往往需要多次调参尝试才能成功训练模型。（2） 若攻击模型采用二阶段生成方法，如CFGAN，第二阶段依赖于第一阶段的输出图像，两个阶段无法同时进行，所需要的时间开销大，模型训练效率不高。
\par
针对以上问题，需要针对高效率的图像特征反向攻击方法作出研究。一方面，使用更高效的辅助生成方法来进行网络建模，另一方面，寻找开销更小的训练方法来完成图像重建任务。

\subsection{研究方案}
\subsubsection{基于目标引导扩散模型的图像特征反向攻击研究}\label{sec:plan_1}
本研究提出一个高效率的模型反演方法，从公共数据集上训练的一般无条件生成网络，结合图像特征信息的分数作为引导，从而实现高效率的图像特征反向攻击。
\par
首先对图像特征反向攻击问题作出基本假设。记图像特征信息为y，对应的原始未知图像为$x \sim p(x)$，则图像特征信息的分布可以表示为 $p(y|x)$。本课题所研究的目标是对分布$p(x|y)$进行建模。以往的方法采用GAN模型作为生成器，其生成时是一步生成，难以使用分类引导生成。本研究基于扩散模型进行，其前向扩散步骤与反向生成步骤可以表示为公式\eqref{eqn-1}和公式\eqref{eqn-2},
\begin{align}
      q(x_t|x_{0})=\mathcal{N}(x_t;\sqrt{\overline{\alpha}_t}x_{0},(1-\overline{\alpha}_t)I)\label{eqn-1} \\
      x_{t-1}= \frac{1}{\sqrt{\alpha_t}}
      (x_t -
      \frac{1-\alpha_T}{\sqrt{1-\overline{\alpha}_t}}
      (\epsilon_\theta(x_t,t))) + \sigma_t z \label{eqn-2}
\end{align}
\par
其中$z \sim \mathcal{N}(0,I)$，$x_T \sim \mathcal{N}(0,I)$，$\epsilon_\theta$ 是通过训练得到的关于$x_t$和$t$的噪音，$\sigma_t$,$\alpha_t$ 为与扩散时间步t相关的参数，$\alpha_t$和$\overline{\alpha}_t$为前向过程中参数，这些参数会在\ref{sec:finishwork}一节中详细说明。生成过程即通过从随机噪声 $x_T$ 的采样，迭代公式\eqref{eqn-2}，一步一步恢复图像直至 $x_0$ ，完成生成过程。
\par
以上过程为无条件图像重建的过程，接下来增加图像特征信息$y$对生成过程的引导和约束。对于条件概率贝叶斯公式的导数形式，可以有如下表示：
\begin{equation}\label{eqn-3}
      \nabla \log p(x|y) = \nabla \log p(x) + \nabla \log p(y|x)
\end{equation}
\par
其中的 $y$ 表示分类标签，$\nabla \log p(x|y)$ 表示标签条件下的分数估计，而 $\nabla \log p(x)$表示无条件的分数，$\nabla \log p(y|x)$ 这个认为是在此图像$x$的条件下标签的分数估计。使用特威迪公式对扩散模型的采样过程做估计可以得到如下表示：
\begin{equation}\label{eqn-4}
      \sqrt{\overline{\alpha}_t}x_0 = x_t + (1 - \overline{\alpha}_t) \cdot \nabla_x \log p(x_t) = x_t - \sqrt{1-\overline{\alpha}_t}\cdot\epsilon_\theta(x_t,t)
\end{equation}
\par
于是可以推得扩散模型中采样过程的网络输出与模型分数的关联：
\begin{equation}\label{eqn-5}
      \nabla_{x_t} \log p(x_t) = - \frac{1}{\sqrt{1-\overline{\alpha}_t}} \cdot\epsilon_\theta(x_t,t)
\end{equation}
\par
代入公式\eqref{eqn-3}，得到以下结果：
\begin{equation}\label{eqn-6}
      \nabla \log p(x|y) = - \frac{1}{\sqrt{1-\overline{\alpha}_t}} \cdot\epsilon_\theta(x_t,t)
      + \nabla \log p(y|x)
\end{equation}
\par
若将$p(x|y)$视为生成过程，那么其与模型分数的关联可以表示为：
\begin{equation}\label{eqn-7}
      \nabla \log p(x|y) = - \frac{1}{\sqrt{1-\overline{\alpha}_t}} \cdot\hat{\epsilon}_\theta(x_t,t)
\end{equation}
\par
联合公式\eqref{eqn-6}，则得到以下表达：
\begin{equation}\label{eqn-8}
      \hat{\epsilon}_\theta(x_t,t) = \epsilon_\theta(x_t,t) -\sqrt{1-\overline{\alpha}_t} \cdot \nabla \log p(y|x)_\theta(x_t,t)
\end{equation}
\par
其中，公式\eqref{eqn-8}等号右边第一项为扩散模型原本的模型噪声输出，右边第二项可以认为是在当前图像上的模型图像分类器分数，而等号左边则为分类器分数调整后的模型噪声修正。
\subsubsection{基于多模态模型微调的图像特征反向攻击研究}
多模态模型是指能够同时处理多种类型数据，如文本、图像、视频等模态的大型神经网络模型。多模态模型可以划分为5个部分，模态编码器，大语言模型，模态解码器，以及两两之间的输入映射器和输出映射器。
\par
模态编码过程可以用$F_X = ME_X(I_X)$来表示，其中$X$表示模态，$ME_X$表示$X$模态的编码器，$I_X$表示该模态的输入。输入映射模块的任务是把多模态编码模块得到的$F_X$对齐到文本特征空间，得到$P_X$，然后再与文本$t$特征$F_T$作为LLM的输入。给定配对的数据集$\{I_X,t\}$，输入映射模块的训练目标是：
\begin{equation}\label{eqn-9}
      \arg \min \mathcal{L}(LLM(P_X,F_X),t)
\end{equation}
\par
大语言模型作为核心，负责产生推理、上下文学习、链式思考、遵从指令的能力。它要产生文本和其他模态的基本理解单位tokens。这些tokens作为指令要决定是否产生其他模态的内容，如果是，则要产生相应的内容信号。大语言模型的处理过程可以写成：
\begin{equation}\label{eqn-10}
      t,S_X = LLM(P_X,F_T)
\end{equation}
\par
用输出模块将$S_X$映射到$H_X$，再把$H_X$作为后续多模态生成器的输入，最终模态生成器把$H_X$处理成特定的模态数据。
\par
根据以上多模态大模型的结构特点，可以使用微调技术训练多模态大模型，使其接受图像特征信息，并能将其对齐到文本特征空间，从而利用LLM能力进行图像及后续的多模态生成器进行图像重建任务。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{预期达到的目标}
预期目标可分为两个阶段：
（1）完成条件引导扩散模型构建以及训练过程，使其能够接受未知图像的图像特征，从图像特征出发重建出尽可能与原图像相似的图像。
（2）使用微调方法对当前已有的预训练多模态模型进行训练，使其具备理解图像特征的能力，并能够从图像特征出发尽可能重建原图像。
\section{已完成的研究工作与进度安排}
\subsection{已完成的研究工作和取得的研究成果}\label{sec:finishwork}
本节主要介绍本课题已完成工作内容，主要包括典型图像特征提取技术与图像生成模型的基础理论学习成果，其中图像生成模型又可分为无条件生成模型与有条件生成模型工作原理两部分，这些理论为后续的实验设计与验证分析提供指导作用。
\subsubsection{典型图像特征提取技术}
典型图像特征提取技术包括SIFT，HOG，LBP，下面分别简要说明各方法提取图像特征的步骤.
\par
SIST特征的提取主要涉及四个步骤：
\par
（1）构建尺度空间：通过对图像进行高斯模糊，生成一系列尺度空间，然后计算不同尺度之间的差分，得到高斯差分图，用于检测不同尺度下的关键点。
（2）准确的关键点定位：通过比较高斯差分图中采样点相同尺度的周围8个像素与相邻尺度的9个像素的值来获得候选特征点集。
（3）方向分配：‌计算每个关键点的梯度方向直方图，赋予主要方向，以保证SIFT特征的旋转不变性。
（4）关键点描述符生成：计算以特征点为中心的16 x 16局部区域中8个方向的梯度信息，最终生成128维特征描述符。
\par
定向梯度直方图特征HOG通过以下步骤工作：‌
（1）图像预处理：包括灰度化和Gamma校正，以减少光照和噪声的影响。
（2）‌梯度计算：‌计算图像中每个像素点的梯度大小和方向
（3）划分连通区域单元：‌将图像划分为多个小的单元，每个单元包含若干像素点。
（4）构建直方图：‌在每个单元内，根据像素点的梯度方向构建方向梯度直方图，统计梯度方向的分布。
（5）组合块并归一化：将多个单元组合成更大的块，对每个块内的直方图进行归一化处理，以进一步减少光照和对比度的影响。
（6）特征向量生成：将所有块的归一化直方图组合起来，形成整幅图像的HOG特征向量
\par
局部二值模式特征算法：
\par
首先定义一个窗口‌，以窗口中心的像素为阈值。然后，将相邻的8个像素的灰度值与中心像素的灰度值进行比较。如果周围像素的灰度值大于或等于中心像素的灰度值，则该像素点被标记为1，否则为0。这样，8个相邻像素的比较结果可以产生一个8位的二进制数，这个二进制数就是中心像素的LBP值，反映了该区域的纹理信息。
\subsubsection{无条件扩散模型理论}\label{sec:DDPM}
无条件扩散模型模型包含两个过程，前向扩散过程和反向生成过程，下面进行详细分析。
前向扩散过程是指的对数据逐渐增加高斯噪音直至数据变成随机噪音的过程。
\begin{equation}\label{eqn-11}
      q(x_t|x_{t-1})=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_tI)
\end{equation}
\par
其中$\{\beta_t\}^{T}_{t=1}$为每一步所采用的方差，介于$0 \sim 1$之间。通常情况下，越后面的时间步会采用更大的方差。如果扩散步数T足够大，那么最终得到的$x_T$就完全丢失了原始数据而变成了一个随机噪音。扩散过程的每一步都生成一个带噪音的数据，整个扩散过程也就是一个马尔卡夫链：
\begin{equation}\label{eqn-12}
      q(x_{1:T}|x_0) = \Pi^T_{t=1}{q(x_t|x_{t-1})}
\end{equation}
\par
扩散过程的一个重要特性是可以直接基于原始数据来对任意t步的$x_t$进行采样：$x_t \sim q(x_t|x_0)$。
定义$\alpha_t = 1 - \beta_t$和$\overline{\alpha}_t=\Pi^t_{i=1}{\alpha_i}$，通过反复使用重参数技巧，每次重参数都随机从标准高斯分布中采样，再将采样值作为噪声在数据中扩散，那么有：
\begin{align}
x_t &= \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon_{t-1} \nonumber\\
    &= \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1-\alpha_t}\epsilon_{t-1} \nonumber\\
    &= \sqrt{\alpha_t\alpha_{t-1}}x_{t-2} + \sqrt{\sqrt{\alpha_t-\alpha_t\alpha_{t-1}^2}+ \sqrt{1-\alpha_t}^2}\overline{\epsilon}_{t-2}; \nonumber\\
    &= \sqrt{\alpha_t\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}}\overline{\epsilon}_{t-2} \nonumber\\
    &= \cdots \nonumber\\
    &= \sqrt{\overline{\alpha}_t}x_{0} + \sqrt{1-\overline{\alpha}_t}\epsilon \label{eqn-13}
\end{align}
\par
于是可以得到以下表示:
\begin{equation}\label{eqn-14}
      q(x_t|x_{0})=\mathcal{N}(x_t;\sqrt{\overline{\alpha}_t}x_{0},(1-\overline{\alpha}_t)I)
\end{equation}
\par
扩散过程是将数据噪音化，那么反向过程就是一个去噪的过程，如果反向过程的每一步的真实分布$q(x_{t-1}|x_t)$已知，那么从一个随机噪音$x_T \sim \mathcal{N}(0,I)$开始，逐渐去噪就能生成一个真实的样本，所以反向过程也就是生成数据的过程。
估计分布$q(x_{t-1}|x_t)$需要用到整个训练样本，可以用神经网络来估计这些分布。这里将反向过程也定义为一个马尔卡夫链，只不过它是由一系列用神经网络参数化的高斯分布来组成：
\begin{align}
      p_{\theta}(x_{0:T}) &= p(X_T)\Pi^T_{t=1}{p_{\theta}(x_{t-1}|x_t)} \label{eqn-15}\\
      p(x_T) &= \mathcal{N}(x_T;0,I)\label{eqn-16}\\
      p_{\theta}(x_{t-1}|x_t) &= \mathcal{N}(x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))\label{eqn-17}
\end{align}
\par
分布是$q(x_{t-1}|x_t)$不可直接处理的，但是加上条件$x_0$的后验分布$q(x_{t-1}|x_t,x_0)$却是可处理的。
利用贝叶斯公式，得到以下结果：
\begin{equation}\label{eqn-18}
      q(x_{t-1}|x_t,x_0) = q(x_{t}|x_{t-1},x_0)\frac{q(x_{t-1}|x_0)}{q(x_{t}|x_0)}
\end{equation}
\par
这里利用马尔可夫链性质，可知第一项与$x_0$无关，分式两项可以从前向过程得到。因此可以计算。再利用公式\eqref{eqn-14}及公式\eqref{eqn-18}，可以证明$q(x_{t-1}|x_t,x_0)$是一个高斯分布，这里表示为:
\begin{equation}\label{eqn-19}
      q(x_{t-1}|x_t,x_0) = \mathcal{N}(x_{t-1};\widetilde{\mu}(x_t,x_0),\widetilde{\beta_t}I)
\end{equation}
\par
最终可以得到:
\begin{align}
      \widetilde{\beta_t} &= \frac{1 - \overline{\alpha}_{t-1}}{1 - \overline{\alpha}_{t}}\beta_t \label{eqn-20}\\
      \widetilde{\mu}(x_t,x_0) &= \frac{\sqrt{\alpha_t}(1- \overline{\alpha}_{t-1})}{1- \overline{\alpha}_{t}}x_t + \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1- \overline{\alpha}_{t}}x_0 \label{eqn-21}
\end{align}
\par
可以看到由于扩散过程参数固定，方差是一个定量，而均值是一个依赖$x_0$和$x_t$的函数。
\par
上面介绍了扩散模型的扩散过程和反向过程，现在从另外一个角度来看扩散模型：如果把中间产生的变量看成隐变量的话，那么扩散模型其实是包含$T$个隐变量的隐变量模型，它可以看成是一个特殊的层次化的VAE，相比VAE来说，扩散模型的隐变量是和原始数据同维度的，而且扩散过程是固定的。既然扩散模型是隐变量模型，那么就可以基于变分推断常用的证据下界ELBO作为最大化优化目标，这里有：
\begin{align}
      \log{p_{\theta}(x_0)} &= \log{\int{p_{\theta}(x_{0:T})dx_{1:T}}};\nonumber\\
      &=\log{\int{\frac{p_{\theta}(x_{0:T})q(x_{1:T}|x_0)}{q(x_{1:T}|x_0)}dx_{1:T}}} \nonumber\\
      &\ge \mathbb{E}_{q(x_{1:T}|x_0)}[\log{\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}}]\nonumber
\end{align}
\par
则训练目标为：
\begin{equation}\label{eqn-22}
L = - L_{VLB} = \mathbb{E}_{q(x_{1:T}|x_0)}[-\log{\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}}] = \mathbb{E}_{q(x_{1:T}|x_0)}[\log{\frac{q(x_{1:T}|x_0)}{p_{\theta}(x_{0:T})}}]
\end{equation}
\par
最终得到：
\begin{align}
      L &= \underbrace{D_{KL}(q(x_T|x_0) || p_\theta(x_T))}_{L_T} \nonumber\\
      &+ \sum^T_{t=2}{\underbrace{\mathbb{E}_{q(x_t|x_0)}[D_{KL}(q(x_{t-1}|x_t,x_0) || p_\theta(x_{t-1}|x_t))]}_{L_{t-1}}} \nonumber\\
      &- \underbrace{\mathbb{E}_{q(x_1|x_0)}\log{p_\theta(x_0|x_1)}}_{L_0} \label{eqn-23}
\end{align}
\par
在这里对模型做进一步简化，采用固定的方差$\Sigma_\theta=\sigma^2_tI$，利用高斯分布计算KL散度的公式，经推导优化目标$L_{t-1}$可以变换为：
\begin{equation}\label{eqn-24}
L_{t-1}=\mathbb{E}_{q(x_t|x_0)}[\frac{1}{2\sigma^2_t}\Vert \widetilde{\mu}_t(x_t,x_0)-\mu(x_t,t) \Vert^2]
\end{equation}
\par
从上述公式来看，扩散模型希望网络学习到的均值和后验分布的均值一致。从另外一个角度利用重新参数化技巧。在对$q ( x_t | x_0 )$形式的推导以及公式\eqref{eqn-13}中，重新整理结果，将$x_0$视为变量，来得到以下结果：
\begin{equation}\label{eqn-25}
      x_0 = \frac{x_t - \sqrt{1-\overline{\alpha}_t}\epsilon_0}{\sqrt{\overline{\alpha}_t}}
\end{equation}
\par
将其代入我们之前推导的去噪转移均值公式\eqref{eqn-21}，利用新得到的表达式代入公式\eqref{eqn-23}可以重新推导优化目标$L_{t-1}$为：
\begin{equation}\label{eqn-26}
      L_{t-1}=\mathbb{E}_{x_0,\epsilon \sim \mathcal{N}(0,I)}[\lVert \epsilon - \epsilon_\theta (\sqrt{\overline{\alpha}_t}x_0 + \sqrt{1 - \overline{\alpha}_t}\epsilon,t)\rVert^2_2]
\end{equation}
\par
以上结果表明通过预测原始图像$x_0$的学习目标来训练扩散模型等价于通过学习预测噪声来进行训练。
\subsubsection{基于得分函数的扩散模型解释与条件引导生成}
对于一个高斯变量$z\sim \mathcal{N} ( z ; \mu_z , \Sigma_z)$，特威迪公式为：
\begin{equation}\label{eqn-27}
\mathbb{E}[\mu_z | z] = z + \Sigma_z\nabla_z\log{p(z)}
\end{equation}
\par
由之前的结果，可以得到：
\begin{equation}\label{eqn-28}
      q(x_t|x_0) = \mathcal{N}(x_t;\sqrt{\overline{\alpha}_t}x_0,(1-\overline{\alpha}_t)I)
\end{equation}
\par
然后，应用特威迪公式来预测给定样本的$x_t$的真实后验均值：
\begin{equation}\label{eqn-29}
  \mathbb{E}[\mu_{x_t} | x_t] = x_t + (1-\overline{\alpha}_t)\nabla_{x_t}\log{p(x_t)}
\end{equation}
\par
根据特威迪公式，真实均值最佳估计定义为：
\begin{align}
  \sqrt{\overline{\alpha}_t}x_0 = x_t + (1-\overline{\alpha}_t)\nabla_{x_t}\log{p(x_t)} \label{eqn-30} \\
  x_0 =\frac{ x_t + (1-\overline{\alpha}_t)\nabla_{x_t}\log{p(x_t)}}{\sqrt{\overline{\alpha}_t}} \label{eqn-31}
\end{align}
\par
然后，我们可以将上述方程再次代入\ref{sec:DDPM}节的$\widetilde{\mu}(x_t,x_0)$并推导出新优化目标的形式：
\begin{equation}\label{eqn-32}
      L_{t-1}=\mathbb{E}_{x_0,\epsilon \sim \mathcal{N}(0,I)}[\lVert s_\theta(x_t,t) - \nabla \log p(x_t)\rVert^2_2]
\end{equation}
\par
这里可以认为训练扩散模型可以通过学习预测得分函数$\nabla_{x_t}\log{p(x_t)}$来优化。得分函数是对于任意的噪声水平$t$，$x_t$在数据空间的梯度。
\par
以上过程中只对无条件数据分布$p ( x )$进行了建模。然而，如果希望通过条件信息y显式地控制生成的数据，需要学习条件分布$p ( x | y )$。从扩散模型的基于得分的表述开始，我们的目标可以视为是在任意噪声水平t下学习条件模型的得分$\nabla \log p ( x_t | y )$。根据贝叶斯法则，可以推导出如下等价形式。其中，$\log p ( y )$关于$x_t$的梯度为零。
\begin{align}
  \nabla \log p (x_t|y)
  &= \nabla \log \frac{
    p(x_t)p(y|x_t)
  }{
    p(y)
  } \nonumber\\
  &= \nabla \log p(x_t) + \nabla \log p(y|x_t) + \nabla \log p(y) \nonumber\\
  &= \nabla \log p(x_t) + \nabla \log p(y|x_t) \label{eqn-33}
\end{align}
\par
我们的最终推导结果可以理解为学习一个无条件的得分函数，结合分类器的对抗梯度。因此，在分类器指导中，无条件扩散模型的得分与前面推导的一样被学习，同时一个分类器接受任意噪声$x_t$并试图预测条件信息$y$。然后，在采样过程中，用于朗之万动力学的整体条件得分函数被计算为无条件得分函数和噪声分类器的对抗梯度之和。
\subsection{进度安排}
      2024.06-2024.08\quad 查阅相关文献，确定课题内容及方案。
\par  2024.08-2024.10\quad 对现有图像特征反向攻击算法进行研究与分析,实现先前工作，完善论文框架。
\par  2024.10-2025.05\quad 探索分析现有扩散模型及算法，应用于图像特征反向攻击进行实验，与已有算法进行对比分析。
\par  2025.05-2025.09\quad 设计基于多模态模型的微调方法，利用多模态模型加速图像特征反向攻击实现。
\par  2025.09-2025.12\quad 撰写毕业论文，准备答辩。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{为完成课题已具备和所需的条件和经费}
为完成本课题，需要如下条件：（1）可供实验使用并带有高性能显卡的计算服务器；（2）Pytorch、Pycharm等软件开发平台与工具；目前以上条件均满足。信息对抗研究所对于本课题给予了充分支持，经费充足。且实验室具有良好的学术氛围与研讨环境，充分支持本课题研究。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{预计研究过程中可能遇到的困难、问题，以及解决的措施}
课题可能遇到的困难：
\par （1） 在大规模数据集或大模型条件下的实验可能对算力要求较高，实验进度缓、周期长；
\par （2） 对理论到实践的过程掌握不够，理论实践困难；
\par 解决途径
\par （1）通过使用高性能计算设备、高性能显卡并行加速计算速度，使用高效的辅助工具实现类库提升计算效率；
\par （2）加强学习先前工作的实践过程，学习他人从理论到实际的转换方法。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{主要参考文献}
\bibliographystyle{hithesis}
\bibliography{reference}

% Local Variables:
% TeX-master: "../report"
% TeX-engine: xetex
% End: